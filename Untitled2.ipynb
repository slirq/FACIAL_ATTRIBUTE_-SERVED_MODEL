{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import random\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from shutil import copyfile\n",
    "from os import getcwd\n",
    "import keras\n",
    "import pandas as pd\n",
    "print(tf.version.VERSION)\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./list_attr_celeba.csv')\n",
    "#data.set_index('image_id', inplace=True)\n",
    "data.replace(to_replace=-1, value=0, inplace=True) \n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features  = ['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes',\n",
    "       'Bald', 'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair',\n",
    "       'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin',\n",
    "       'Eyeglasses', 'Goatee', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones',\n",
    "       'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard',\n",
    "       'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline',\n",
    "       'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair',\n",
    "       'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick',\n",
    "       'Wearing_Necklace', 'Wearing_Necktie', 'Young']\n",
    "\n",
    "class celeb_dataframe():\n",
    "    '''Wraps the celebA dataset, allowing an easy way to:\n",
    "       - Select the features of interest,\n",
    "       - Split the dataset into 'training', 'test' or 'validation' partition.\n",
    "    '''\n",
    "    def __init__(self,main_folder = \"./\" , selected_features = [] , drop_features = []):\n",
    "        self.main_folder = main_folder\n",
    "        self.images_folder   = os.path.join(main_folder, './img_align_celeba/img_align_celeba')\n",
    "        self.attr_path = os.path.join(main_folder , \"list_attr_celeba.csv\")\n",
    "        self.features_name = []\n",
    "        self.prepare(drop_features , selected_features)\n",
    "        \n",
    "    def prepare(self,drop_features, selected_features ):\n",
    "        \n",
    "        #attributes selection\n",
    "        if len(selected_features) == 0  :\n",
    "            self.attributes = pd.read_csv(self.attr_path)\n",
    "            self.num_features = 40\n",
    "        else:\n",
    "            self.num_features = len(selected_features)\n",
    "            selected_features = selected_features.copy()\n",
    "            selected_features.append(\"image_id\")\n",
    "            self.attributes = pd.read_csv(self.attr_path)[selected_features]\n",
    "        \n",
    "        #removing features\n",
    "        if len(drop_features) != 0:\n",
    "            for feature in drop_features:\n",
    "                if feature in self.attributes:\n",
    "                    self.attributes = self.attributes.drop(feature , axis = 1)\n",
    "                    self.num_features -= 1\n",
    "            \n",
    "        self.attributes.set_index(\"image_id\" , inplace = True)\n",
    "        self.attributes.replace(to_replace = -1 , value = 0 , inplace = True)\n",
    "        self.attributes[\"image_id\"] = list(self.attributes.index)\n",
    "        self.features_name = list(self.attributes.columns)[:-1]\n",
    "        \n",
    "        return self.attributes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeb_df = celeb_dataframe()\n",
    "celeb = celeb_df.prepare(drop_features=[],selected_features= features) #taking all the features for training.\n",
    "celeb.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_ind = int((1 - 0.2) * celeb.shape[0])\n",
    "train_df = celeb[:split_ind]\n",
    "validation_df = celeb[split_ind:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rotation_range=20, \n",
    "                                   rescale=1./255, \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2, \n",
    "                                   shear_range=0.2, \n",
    "                                   zoom_range=0.2, \n",
    "                                   horizontal_flip=True, \n",
    "                                   fill_mode='nearest'\n",
    "                                    )\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale= 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    directory=celeb_df.images_folder,\n",
    "    x_col='image_id',\n",
    "    y_col=celeb_df.features_name,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode='raw',\n",
    "    shuffle = True\n",
    ")\n",
    "\n",
    "validation_generator = valid_datagen.flow_from_dataframe(dataframe=validation_df,\n",
    "                                                         directory=celeb_df.images_folder,\n",
    "                                                         x_col='image_id',\n",
    "                                                         y_col=celeb_df.features_name,\n",
    "                                                         target_size=(224, 224),\n",
    "                                                         batch_size=32,\n",
    "                                                         class_mode='raw'\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model =tf.keras.models.Sequential([\n",
    "    tf.keras.applications.MobileNetV2(include_top=False,weights=None,input_shape=(170,170,3), pooling='avg'),\n",
    "    tf.keras.layers.Dense(1536, activation='relu'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(40, activation='sigmoid')\n",
    "    \n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy', metrics='binary_accuracy')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "        def on_epoch_end(self,epoch,logs={}):\n",
    "            if(logs.get('val_acc') > 0.90):\n",
    "                print(\"\\n Reached 90% accuracy so cancelling training!\")\n",
    "                self.model.stop_training=True\n",
    "callbacks=myCallback()\n",
    "\n",
    "\n",
    "model.fit_generator(train_generator,\n",
    "                              epochs=5,\n",
    "                              verbose=1,\n",
    "                              validation_data=validation_generator)#,callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mymodelcelebface.h5',overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and validdation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFERENCE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0529 20:42:50.877701 14212 def_function.py:120] 11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000136605B6BF8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blurry=58.75%\n",
      "Wearing_Hat=32.75%\n",
      "No_Beard=5.95%\n",
      "Young=5.5%\n",
      "Smiling=4.43%\n",
      "Wavy_Hair=3.32%\n",
      "Mouth_Slightly_Open=2.91%\n",
      "Mustache=2.13%\n",
      "Bags_Under_Eyes=1.7%\n",
      "Straight_Hair=1.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0529 20:42:57.431994 14212 def_function.py:120] 11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001363D98D730> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blurry=55.37%\n",
      "Wearing_Hat=37.32%\n",
      "No_Beard=6.44%\n",
      "Young=5.88%\n",
      "Smiling=4.75%\n",
      "Mouth_Slightly_Open=3.33%\n",
      "Wavy_Hair=3.21%\n",
      "Mustache=2.18%\n",
      "Bags_Under_Eyes=1.92%\n",
      "Straight_Hair=1.77%\n"
     ]
    }
   ],
   "source": [
    "features  = ['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes',\n",
    "       'Bald', 'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair',\n",
    "       'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin',\n",
    "       'Eyeglasses', 'Goatee', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones',\n",
    "       'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard',\n",
    "       'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline',\n",
    "       'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair',\n",
    "       'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick',\n",
    "       'Wearing_Necklace', 'Wearing_Necktie', 'Young']\n",
    "\n",
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    if cv2.waitKey(2500) & 0xFF == ord('q'):\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    \n",
    "    ret,frame=cap.read()\n",
    "    model=tf.keras.models.load_model(r'mymodelcelebface.h5')# load model\n",
    "    if ret==True:\n",
    "        img = cv2.resize(frame,(170,170)) \n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(img, axis=0)\n",
    "\n",
    "        images = np.vstack([x])\n",
    "        classes = model.predict(x, batch_size=1)\n",
    "        classes=classes[0]\n",
    "       \n",
    "        top=np.argsort(classes)[-11:][::-1]#print top 10 most confident predication irrespective of gender\n",
    "        for i in range(1,11):\n",
    "            perc=str(round((classes[top[i]]*100),2))\n",
    "            print(str(features[top[i]])+\"=\"+perc+\"%\")\n",
    "        \n",
    "        \n",
    "    cv2.imshow(\"output\",frame)\n",
    "    \n",
    "      \n",
    "# Break the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
